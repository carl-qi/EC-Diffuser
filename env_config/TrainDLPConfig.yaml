# DLP Training Configuration

ds: "franka_kitchen"
data_root_dir: 'data_dlp/franka_kitchen'  # format in dlp2/process_dlp_data.py

lr: 0.0002
batch_size: 64
num_epochs: 250
load_model: False
eval_epoch_freq: 1
n_kp: 1  # num kp per patch
kp_range: [-1, 1]
weight_decay: 0.0
run_prefix: ""
pad_mode: 'replicate'
sigma: 1.0  # default sigma for the gaussian maps
dropout: 0.0
kp_activation: "tanh"
warmup_epoch: 1
eval_im_metrics: False

beta_kl: 0.1  # original
beta_rec: 1.0
scale_std: 0.3  # default
offset_std: 0.2  # default
n_kp_enc: 40  # total kp to output from the encoder / filter from prior
n_kp_prior: 128
patch_size: 8 # prior patch size need to be lower than posterior patch size: posterior is (image size * anchor_s)
learned_feature_dim: 4  # latent visual features for each kp (excluding bg)
bg_learned_feature_dim: 1
topk: 10  # display top-10 kp with the smallest variance
recon_loss_type: "mse"
anchor_s: 0.125   # reduce this to 0.125 for small glimpses
kl_balance: 0.001
  
# VGG LOSS
# loss to vgg
# beta_kl to 40
